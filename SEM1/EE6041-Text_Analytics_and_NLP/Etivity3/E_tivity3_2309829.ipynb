{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   **Name:** Muhammad Khubaib Akram\n",
        "2.   **Student ID:** 23098929\n",
        "\n"
      ],
      "metadata": {
        "id": "fJJmzAheCS7m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Zh9oXGXCNRa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TASK 1"
      ],
      "metadata": {
        "id": "ZB6YlT5cDu62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complete the following code snippet to download unigrams and bigrams data, and load them into their corresponding dataframes, unigrams_df and bigrams_df\n",
        "\n",
        "YOUR CODE HERE\n",
        "\n",
        "\n",
        "print(f'Number of unigrams:totalUnigrams} Number of Bigrams: {totalBigrams}')\n",
        "     display(unigrams_df.head(100),bigrams_df.head(100))\n"
      ],
      "metadata": {
        "id": "2NMn-ycWD2ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_uni = \"https://norvig.com/ngrams/count_1w.txt\"\n",
        "\n",
        "unigrams_df = pd.read_csv(url_uni, sep=\"\\t\", header=None)\n",
        "totalUnigrams = unigrams_df[1].size"
      ],
      "metadata": {
        "id": "jEohsp4gC2s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_bi = \"https://norvig.com/ngrams/count_2w.txt\"\n",
        "bigrams_df = pd.read_csv(url_bi,header=None, delim_whitespace=True)\n",
        "bigrams_df.head()\n",
        "totalBigrams = bigrams_df[2].size\n",
        "print(f'Number of unigrams:{totalUnigrams} Number of Bigrams: {totalBigrams}')\n",
        "print(unigrams_df.head(100))\n",
        "print(bigrams_df.head(100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9tpDkZ1Dkmm",
        "outputId": "83098dc8-6bf1-484d-8c74-fb0bead9f322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unigrams:333333 Number of Bigrams: 286358\n",
            "          0            1\n",
            "0       the  23135851162\n",
            "1        of  13151942776\n",
            "2       and  12997637966\n",
            "3        to  12136980858\n",
            "4         a   9081174698\n",
            "..      ...          ...\n",
            "95     like    520585287\n",
            "96  service    519537222\n",
            "97        x    508609523\n",
            "98     than    502609275\n",
            "99     find    502043038\n",
            "\n",
            "[100 rows x 2 columns]\n",
            "          0            1       2\n",
            "0   0Uplink     verified  523545\n",
            "1       0km           to  116103\n",
            "2     1000s           of  939476\n",
            "3      100s           of  539389\n",
            "4     100th  anniversary  158621\n",
            "..      ...          ...     ...\n",
            "95     24th           of  327460\n",
            "96     25th  anniversary  261023\n",
            "97     25th           of  397735\n",
            "98     26th           of  271707\n",
            "99     27th           of  276619\n",
            "\n",
            "[100 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2WiYI8noUVKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B-\n",
        "\n",
        "Complete the function below such that it computes the probability of a given sentence using the unigram and bigram counts from (a). Do not apply add-one smoothing [3 marks]\n",
        "\n",
        "\n",
        "def probability(sentence):\n",
        "\n",
        "YOUR CODE HERE\t   \n",
        "\n",
        "   \treturn sentenceProbability\n",
        "\n",
        "probability(\"i love you\")>probability('i hate you'"
      ],
      "metadata": {
        "id": "zb-uqly9JYN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def probability(sentence):\n",
        "  sen = sentence.split(\" \")\n",
        "  bi_count = 0\n",
        "  uni_count = 0\n",
        "  prob = 0\n",
        "  for i in range(len(sen)-1):\n",
        "\n",
        "  # finding unigram count\n",
        "    uni_filter = unigrams_df.loc[unigrams_df[0][:] == sen[0]]\n",
        "    uni_count = int(uni_filter[1].values)\n",
        "    print(f\"uni gram count for {sen[i]} is {uni_count}\")\n",
        "  # finding bi gram count\n",
        "    bi_filter = bigrams_df.loc[(bigrams_df[0][:] == sen[i]) & (bigrams_df[:][1] == sen[i+1])]\n",
        "    bi_count = int(bi_filter[2].values)\n",
        "    print(f\"uni gram count for '{sen[i]} {sen[i+1]}  is {uni_count}\")\n",
        "    #print(bigrams_df.loc[(bigrams_df[0][:] == sen[i]) & (bigrams_df[:][1] == sen[i+1])])\n",
        "    print(\"---------------------\")\n",
        "    prob +=  bi_count/uni_count\n",
        "  print(f\"probability of {sen} is {prob}\")\n",
        "  print(\"***********\")\n",
        "  return prob\n",
        "\n",
        "probability(\"i love you\") > probability('i hate you')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yi2u6cNHud3",
        "outputId": "d78c3b94-ea38-4cd5-e24e-8f6c691d2a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uni gram count for i is 3086225277\n",
            "uni gram count for 'i love  is 3086225277\n",
            "---------------------\n",
            "uni gram count for love is 3086225277\n",
            "uni gram count for 'love you  is 3086225277\n",
            "---------------------\n",
            "probability of ['i', 'love', 'you'] is 0.0030483925039798705\n",
            "***********\n",
            "uni gram count for i is 3086225277\n",
            "uni gram count for 'i hate  is 3086225277\n",
            "---------------------\n",
            "uni gram count for hate is 3086225277\n",
            "uni gram count for 'hate you  is 3086225277\n",
            "---------------------\n",
            "probability of ['i', 'hate', 'you'] is 0.0004473617043737277\n",
            "***********\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###C\n",
        "Copy the function from (b) to a new cell, and modify it such that it applies\n",
        " add-one smoothing. Your new function should also address the problem of underflow\n",
        " When computing the sentence Probability [2 marks]"
      ],
      "metadata": {
        "id": "RGUgTzfYCR3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unigrams_df[0].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTjJ8vdYZt5n",
        "outputId": "3fc55614-63c0-44fb-96ca-06b54ffd533a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "333331"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def probability_lap(sentence):\n",
        "  sen = sentence.split(\" \")\n",
        "  bi_count = 0\n",
        "  uni_count = 0\n",
        "  prob = 0\n",
        "  for i in range(len(sen)-1):\n",
        "\n",
        "  # finding unigram count\n",
        "    uni_filter = unigrams_df.loc[unigrams_df[0][:] == sen[0]]\n",
        "    uni_count = int(uni_filter[1].values)\n",
        "    print(f\"uni gram count for {sen[i]} is {uni_count}\")\n",
        "  # finding bi gram count\n",
        "    bi_filter = bigrams_df.loc[(bigrams_df[0][:] == sen[i]) & (bigrams_df[:][1] == sen[i+1])]\n",
        "    bi_count = int(bi_filter[2].values)\n",
        "    print(f\"uni gram count for '{sen[i]} {sen[i+1]}  is {uni_count}\")\n",
        "    #print(bigrams_df.loc[(bigrams_df[0][:] == sen[i]) & (bigrams_df[:][1] == sen[i+1])])\n",
        "    print(\"---------------------\")\n",
        "    prob +=  (bi_count+1) / (uni_count+ unigrams_df[0].nunique() )\n",
        "  print(f\"probability of {sen} is {prob}\")\n",
        "  print(\"***********\")\n",
        "  return prob\n",
        "\n",
        "probability_lap(\"i love you\") > probability_lap('i hate you')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxkrhZvIXYgT",
        "outputId": "89043b57-bafb-4506-84ef-29353b0d7cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uni gram count for i is 3086225277\n",
            "uni gram count for 'i love  is 3086225277\n",
            "---------------------\n",
            "uni gram count for love is 3086225277\n",
            "uni gram count for 'love you  is 3086225277\n",
            "---------------------\n",
            "probability of ['i', 'love', 'you'] is 0.0030480639426756677\n",
            "***********\n",
            "uni gram count for i is 3086225277\n",
            "uni gram count for 'i hate  is 3086225277\n",
            "---------------------\n",
            "uni gram count for hate is 3086225277\n",
            "uni gram count for 'hate you  is 3086225277\n",
            "---------------------\n",
            "probability of ['i', 'hate', 'you'] is 0.0004473140397922423\n",
            "***********\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 3 -\n",
        "\n",
        "I could not complete the task during the lab. I went through multiple codes and I find the Deepak Ramesh code more easy to understand and compact as well."
      ],
      "metadata": {
        "id": "lXy_iM4f9LAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def ShannonVisualization(seed=\"<S>\"):\n",
        "  sentence = seed\n",
        "  current_word = seed\n",
        "  while True:\n",
        "      bigramsPossible = bigrams_df[bigrams_df[0].str.startswith(current_word + \" \")]\n",
        "      if bigramsPossible.empty:\n",
        "          break\n",
        "      next_words = bigramsPossible[0].apply(lambda x: x.split()[1])\n",
        "      prob = bigramsPossible['CountColumn'] / bigramsPossible['CountColumn'].sum()\n",
        "      nextWord = np.random.choice(next_words, p=prob.to_numpy())\n",
        "      sentence += \" \" + nextWord\n",
        "      currentWord = nextWord\n",
        "      print(sentence)\n",
        "\n",
        "  return sentence\n",
        "\n",
        "shannonSentence = ShannonVisualization(\"<S>\")\n",
        "print(\"Shannon Visualization Sentence:\")\n",
        "print(shannonSentence)"
      ],
      "metadata": {
        "id": "9ZQ1EWF6Z_Ah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "5ded52a1-962e-4cd0-c138-3cf233b0e8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-45af054e4e1d>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mshannonSentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShannonVisualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<S>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shannon Visualization Sentence:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshannonSentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-45af054e4e1d>\u001b[0m in \u001b[0;36mShannonVisualization\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcurrent_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mbigramsPossible\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigrams_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbigrams_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_word\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbigramsPossible\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3796\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3797\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3798\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0;31m# Don't raise on e.g. [\"A\", \"B\", np.nan], see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0;31m#  test_loc_getitem_list_of_labels_categoricalindex_with_na\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot mask with non-boolean array containing NA / NaN values"
          ]
        }
      ]
    }
  ]
}