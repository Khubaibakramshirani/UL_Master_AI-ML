{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###TASK 1\n",
        "\n",
        "Given the two confusion tables below, compute\n",
        "Microaveraged precision, recall, and F1\n",
        "Macroaveraged precision, recall, and F1\n",
        "Explain the reason for the difference between the obtained Microaveraged and Macroaveraged F1 measures.\n",
        "\n",
        "Class Food\n",
        "                  |  Truth: YES  |  Truth: NO\n",
        "                                          \n",
        "Classifier: YES   |    800       |    200\n",
        "\n",
        "Classifier: NO    |    200       |    500\n",
        "____________________________________________________\n",
        "\n",
        "Class Drink\n",
        "                  |  Truth: YES  |  Truth: NO\n",
        "                                          \n",
        "Classifier: YES   |    70        |    30\n",
        "\n",
        "Classifier: NO    |    30        |    100\n",
        "\n",
        "\n",
        "Show your work with the help of Latex.\n",
        "Round all numbers to 3 decimal points.\n",
        "Intro to LaTeX: Learn to write beautiful math equations\n",
        "Adding Latex to your notebook\n"
      ],
      "metadata": {
        "id": "QczYziH9dJ0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Given the confusion matrices for two classes, Food and Drink, we calculate the following:\n",
        "\n",
        "Class Food:\n",
        "\n",
        "\\begin{align*}\n",
        "\\text{True Positives (TP)} &= 800 \\\\\n",
        "\\text{False Positives (FP)} &= 200 \\\\\n",
        "\\text{False Negatives (FN)} &= 200 \\\\\n",
        "\\text{Precision} &= \\frac{TP}{TP + FP} = \\frac{800}{800 + 200} = 0.800 \\\\\n",
        "\\text{Recal} &= \\frac{TP}{TP + FN} = \\frac{800}{800 + 200} = 0.800 \\\\\n",
        "\\text{F1 Score} &= 2 \\times \\frac{\\text{Precision} \\times \\text{Recal}}{\\text{Precision} + \\text{Recal}} = 2 \\times \\frac{0.800 \\times 0.800}{0.800 + 0.800} = 0.800\n",
        "\\end{align*}\n",
        "\n",
        "Class Drink:\n",
        "\n",
        "\\begin{align*}\n",
        "  \\text{True Positives (TP)} &= 70 \\\\\n",
        "  \\text{False Positives (FP)} &= 30 \\\\\n",
        "  \\text{False Negatives (FN)} &= 30 \\\\\n",
        "  \\text{Precision} &= \\frac{TP}{TP + FP} = \\frac{70}{70 + 30} = 0.700 \\\\\n",
        "  \\text{Recall} &= \\frac{TP}{TP + FN} = \\frac{70}{70 + 30} = 0.700 \\\\\n",
        "  \\text{F1 Score} &= 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} = 2 \\times \\frac{0.700 \\times 0.700}{0.700 + 0.700} = 0.700\n",
        "  \\end{align*}\n",
        "\n",
        "\n",
        "\n",
        "classes:\n",
        "\n",
        "\\begin{align*}\n",
        "  \\text{Micro TP} &= TP_{\\text{Food}} + TP_{\\text{Drink}} = 800 + 70 = 870 \\\\\n",
        "  \\text{Micro FP} &= FP_{\\text{Food}} + FP_{\\text{Drink}} = 200 + 30 = 230 \\\\\n",
        "  \\text{Micro FN} &= FN_{\\text{Food}} + FN_{\\text{Drink}} = 200 + 30 = 230 \\\\\n",
        "  \\end{align*}\n",
        "\n",
        "**MicroAvegared Class**\n",
        "\n",
        "\\begin{align}\n",
        "  \\text{Microavg precision: } \\frac{800+70}{200+30+800+70}=\\frac{870}{1100}\\approx 0.791\n",
        "    \\\\[2em]\n",
        "  \\text{Microavg recall: } \\frac{800+70}{200+30+800+70}=\\frac{870}{1100}\\approx 0.791\n",
        "  \\\\[2em]\n",
        "  \\text{Microasvg F1: } \\frac{2PR}{P+R}=\\frac{2*0.791*0.791}{0.791+0.791}=\\frac{1.251362}{1.582}=0.791\n",
        "  \\\\[2em]\n",
        "  \\end{align}\n",
        "\n",
        "**MacroAveraged Metrics:**\n",
        "\n",
        "\\begin{align}\n",
        "  \\text{Macroavg precision: } \\frac{\\frac{800}{800+200}+\\frac{70}{70+30}}{2}=\\frac{0.8+0.7}{2} = 0.750\n",
        "  \\\\[2em]\n",
        "  \\text{Macroavg recall: } \\frac{\\frac{800}{800+200}+\\frac{70}{70+30}}{2}=\\frac{0.8+0.7}{2} = 0.750\n",
        "  \\\\[2em]\n",
        "  \\text{Macroavg F1: } \\frac{2PR}{P+R}=\\frac{2*0.750*0.750}{0.750+0.750}=\\frac{1.125}{1.5}= 0.750\n",
        "  \\\\[2em]\n",
        "  \\end{align}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fforilnTgUY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Explanation for the Difference in Micro and Macro F1:**\n",
        "\n",
        "\n",
        "The Micro and Macro F1 scores differ because they take into account class imbalances differently.\n",
        "\n",
        "* The Micro F1 score gives equal importance to each instance, which means that it is more influenced by the larger class (Food).\n",
        "* On the other hand, the Macro F1 score treats each class equally, so it is not dominated by the larger class.\n",
        "\n",
        "In this particular case, the class imbalance causes the Micro F1 score to be higher than the Macro F1 score. This difference highlights the impact of class distribution on these metrics."
      ],
      "metadata": {
        "id": "d9bS1Epox_mR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TASK5.3"
      ],
      "metadata": {
        "id": "2T4_t9ueoNis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def navieBayesClassifier(trainingSet,testSet):\n",
        "\n",
        "  megaDocNeg = []\n",
        "  megaDocPOS = []\n",
        "\n",
        "  VOC = {}\n",
        "  NEG_BOW = {}\n",
        "  POS_BOW = {}\n",
        "\n",
        "  prob_neg = 0\n",
        "  prob_pos = 0\n",
        "\n",
        "  for doc, category in trainingSet:\n",
        "\n",
        "    if category == '-':\n",
        "      megaDocNeg.append(doc)\n",
        "    else:\n",
        "      megaDocPOS.append(doc)\n",
        "\n",
        "    for word in doc.lower().split():\n",
        "\n",
        "      VOC[word] = VOC.get(word, 0) + 1\n",
        "\n",
        "      if category == '-':\n",
        "          NEG_BOW[word] = NEG_BOW.get(word, 0) + 1\n",
        "      else:\n",
        "          POS_BOW[word] = POS_BOW.get(word, 0) + 1\n",
        "\n",
        "  megaDocNeg = ' '.join(megaDocNeg)\n",
        "  megaDocPOS = ' '.join(megaDocPOS)\n",
        "\n",
        "  print(\"megaDocNeg= \", megaDocNeg)\n",
        "  print(\"megaDocPOS= \", megaDocPOS)\n",
        "\n",
        "  prob_neg = sum(NEG_BOW.values()) / (sum(NEG_BOW.values()) + sum(POS_BOW.values()))\n",
        "  prob_pos = sum(POS_BOW.values()) / (sum(NEG_BOW.values()) + sum(POS_BOW.values()))\n",
        "\n",
        "  print(f\"prob_Neg={prob_neg}, prob_POS={prob_pos}\\n\")\n",
        "  print(f\"class_bow_GE={NEG_BOW}\\n\")\n",
        "  print(f\"class_bow_PoS={POS_BOW}\\n\")\n",
        "\n",
        "  print(f\"vocabulary={VOC}\\n\")\n",
        "  print(f\"|vocabulary|={len(VOC)}\\n\")\n",
        "\n",
        "  print(\"-\"*100)\n",
        "\n",
        "  CProbNeg = {}\n",
        "  CProbPOS = {}\n",
        "\n",
        "  for word in VOC:\n",
        "    CProbNeg[word] = (NEG_BOW.get(word, 0) + 1) / (sum(NEG_BOW.values()) + len(VOC))\n",
        "    CProbPOS[word] = (POS_BOW.get(word, 0) + 1) / (sum(POS_BOW.values()) + len(VOC))\n",
        "\n",
        "  for doc, question in testSet:\n",
        "\n",
        "    print('-'*100)\n",
        "    print(f\"Test Document=({doc}, '?')\");\n",
        "\n",
        "    for word in doc.lower().split():\n",
        "\n",
        "      if word in VOC:\n",
        "\n",
        "        prob_neg *= CProbNeg[word]\n",
        "        prob_pos *= CProbPOS[word]\n",
        "\n",
        "        print(f\"\\nWord={word}, ConditionalProbNeg = {CProbNeg[word]},  wordConditionalProbPOS = {CProbPOS[word]}\")\n",
        "\n",
        "    if prob_neg > prob_pos:\n",
        "      inferred_class = '-'\n",
        "    else :\n",
        "      inferred_class = '+'\n",
        "\n",
        "    print(f\"\\ndocProbNEG = {prob_neg},  docProbPOS = {prob_pos}\\nInferred class = '{inferred_class}'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "6oAOrMNyzOpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingSet = [('just plain boring','-'),('entirely predictable and lacks energy','-'),('no surprises and very few laughs','-'),('very powerful','+'),('the most fun film of the summer','+')]\n",
        "testSet = [('predictable with no fun','?')]\n",
        "navieBayesClassifier(trainingSet,testSet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJwmGnqIsQjz",
        "outputId": "02ab2953-f705-48c8-eac1-8a9bf39d0165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "megaDocNeg=  just plain boring entirely predictable and lacks energy no surprises and very few laughs\n",
            "megaDocPOS=  very powerful the most fun film of the summer\n",
            "prob_Neg=0.6086956521739131, prob_POS=0.391304347826087\n",
            "\n",
            "class_bow_GE={'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 1, 'few': 1, 'laughs': 1}\n",
            "\n",
            "class_bow_PoS={'very': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n",
            "\n",
            "vocabulary={'just': 1, 'plain': 1, 'boring': 1, 'entirely': 1, 'predictable': 1, 'and': 2, 'lacks': 1, 'energy': 1, 'no': 1, 'surprises': 1, 'very': 2, 'few': 1, 'laughs': 1, 'powerful': 1, 'the': 2, 'most': 1, 'fun': 1, 'film': 1, 'of': 1, 'summer': 1}\n",
            "\n",
            "|vocabulary|=20\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Test Document=(predictable with no fun, '?')\n",
            "\n",
            "Word=predictable, ConditionalProbNeg = 0.058823529411764705,  wordConditionalProbPOS = 0.034482758620689655\n",
            "\n",
            "Word=no, ConditionalProbNeg = 0.058823529411764705,  wordConditionalProbPOS = 0.034482758620689655\n",
            "\n",
            "Word=fun, ConditionalProbNeg = 0.029411764705882353,  wordConditionalProbPOS = 0.06896551724137931\n",
            "\n",
            "docProbNEG = 6.194745086239701e-05,  docProbPOS = 3.2088593039984174e-05\n",
            "Inferred class = '-'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TASK3"
      ],
      "metadata": {
        "id": "FAwcn30kdKfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import textblob\n"
      ],
      "metadata": {
        "id": "SdHksMZudLDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def sentimentAnalyzer(str):\n",
        "\n",
        "  blob = TextBlob(str)\n",
        "  sentiment = blob.sentiment\n",
        "\n",
        "  print()\n",
        "  print(str)\n",
        "  print()\n",
        "\n",
        "  print(\"Sentiment:\", sentiment)\n",
        "\n",
        "  polarity = sentiment.polarity\n",
        "  subjectivity = sentiment.subjectivity\n",
        "\n",
        "  if polarity < -0.2:\n",
        "    print(\"negative sentiment \\U0001F641\")\n",
        "\n",
        "  elif polarity > 0.2:\n",
        "    print(\"positive Sentiment \\U0001F60A\")\n",
        "\n",
        "  else:\n",
        "    print(\"neutral Sentiment: \\U0001F610\")\n",
        "\n",
        "  print(f\"Subjectivity={subjectivity}\")\n",
        "  print(\"-\"*100)\n",
        "\n",
        "\n",
        "sentimentAnalyzer(\"NLP is cool!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QkHid5Jil2S",
        "outputId": "31e20b94-f9c4-4b9f-dee3-a0c77fb5c7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NLP is cool!\n",
            "\n",
            "Sentiment: Sentiment(polarity=0.4375, subjectivity=0.65)\n",
            "positive Sentiment 😊\n",
            "Subjectivity=0.65\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentimentAnalyzer(\"The Earth cannot be flat.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juNQ42T4w-Qo",
        "outputId": "127bc376-5264-4df5-c3f3-1ed30fc34107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The Earth cannot be flat.\n",
            "\n",
            "Sentiment: Sentiment(polarity=-0.025, subjectivity=0.125)\n",
            "neutral Sentiment: 😐\n",
            "Subjectivity=0.125\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentimentAnalyzer(\"NLP is cool!\")\n",
        "sentimentAnalyzer(\"NLP is cool and useful!\")\n",
        "sentimentAnalyzer(\"NLP is hard!\")\n",
        "sentimentAnalyzer(\"NLP is hard and useless!\")\n",
        "sentimentAnalyzer(\"NLP stands for Natural Language processing!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr97aRceinmZ",
        "outputId": "017efdcc-a0ef-4306-97a0-a099498631da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NLP is cool!\n",
            "\n",
            "Sentiment: Sentiment(polarity=0.4375, subjectivity=0.65)\n",
            "positive Sentiment 😊\n",
            "Subjectivity=0.65\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "NLP is cool and useful!\n",
            "\n",
            "Sentiment: Sentiment(polarity=0.3625, subjectivity=0.325)\n",
            "positive Sentiment 😊\n",
            "Subjectivity=0.325\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "NLP is hard!\n",
            "\n",
            "Sentiment: Sentiment(polarity=-0.36458333333333337, subjectivity=0.5416666666666666)\n",
            "negative sentiment 🙁\n",
            "Subjectivity=0.5416666666666666\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "NLP is hard and useless!\n",
            "\n",
            "Sentiment: Sentiment(polarity=-0.45833333333333337, subjectivity=0.37083333333333335)\n",
            "negative sentiment 🙁\n",
            "Subjectivity=0.37083333333333335\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "NLP stands for Natural Language processing!\n",
            "\n",
            "Sentiment: Sentiment(polarity=0.125, subjectivity=0.4)\n",
            "neutral Sentiment: 😐\n",
            "Subjectivity=0.4\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentimentAnalyzer(\"Weather is fine!\")\n",
        "sentimentAnalyzer(\"Weather is good!\")\n",
        "sentimentAnalyzer(\"Weather is bad!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_trN-wllVxu",
        "outputId": "1b58b47a-e942-4ce3-bb82-79491760cefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Weather is fine!\n",
            "\n",
            "Sentiment: Sentiment(polarity=0.5208333333333334, subjectivity=0.5)\n",
            "positive Sentiment 😊\n",
            "Subjectivity=0.5\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Weather is good!\n",
            "\n",
            "Sentiment: Sentiment(polarity=0.875, subjectivity=0.6000000000000001)\n",
            "positive Sentiment 😊\n",
            "Subjectivity=0.6000000000000001\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Weather is bad!\n",
            "\n",
            "Sentiment: Sentiment(polarity=-0.8749999999999998, subjectivity=0.6666666666666666)\n",
            "negative sentiment 🙁\n",
            "Subjectivity=0.6666666666666666\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}