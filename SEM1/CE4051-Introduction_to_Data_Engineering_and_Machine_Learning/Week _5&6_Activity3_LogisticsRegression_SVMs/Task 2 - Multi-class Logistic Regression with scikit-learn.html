<!DOCTYPE html>
<html><head></head><body style="color: rgb(32, 33, 34); font-family: Verdana; font-size: 12pt;"><div>
<h1 role="heading" aria-level="4">Task 2: Multi-class Logistic Regression with scikit-learn</h1>
<p><strong>Weight 25/100</strong></p>
<p>In the second part, we will investigate multi-class classification. Up until now, we have only done binary classification, but as we will see, extending this to multi-class is straightforward.&nbsp;</p>
<ol>
<li>Load all the samples from the Iris dataset, that is iris-setosa, iris-versicolor and iris-virginica. Load the petal length and petal width as the features. Assign the class labels&nbsp;
<ul>
<li>Iris-setosa = 0</li>
<li>Iris-versicolor = 1</li>
<li>Iris-virginica = 2&nbsp;</li>
</ul>
</li>
<li>Use the scikit-learn <code>train_test_split</code> function to split into 30% test and 70% training data
<ul>
<li>Set the <code>stratify</code> parameter to <code>y</code>. The stratify option will make sure that you get the same split of data as is in the original dataset. I.e. you will get 33% of each of the Iris types in your training and test data.</li>
</ul>
</li>
<li>Use the scikit-learn <code>StandardScaler</code> function to apply standard scaling to both training and test data&nbsp;
<ul>
<li>Plot the scaled data&nbsp;</li>
</ul>
</li>
<li>Train an instance of the scikitlearn <code>LogisticRegression</code> algorithm on the provided data.&nbsp;You can use all the default parameters&nbsp;</li>
<li>Plot the decision boundary using the supplied <code>plot_decision_boundary</code> function</li>
<li>Using sklearn's <code>accuracy_score</code>, calculate the accuracy score on the test data&nbsp;</li>
</ol>
<p>Scikit-learn's LogisticRegression class has a parameter to control the regularisation. This parameter is C is the inverse ofâ€¯the regularisation strength, which is described in the SVM videos. Note that the step above where the data is normalised is hugely important, as regularisation only works properly when data is normalised.&nbsp;</p>
<ol>
<li>Plot the decision boundary above when you set C to smaller and larger values (even 0.01 and 100)</li>
<li>Describe what you observe with reference to what you know about regularisation from the material provided&nbsp;</li>
</ol>
</div></body></html>