<!DOCTYPE html>
<html><head>
   <link rel="stylesheet" href="/shared/HTML-Template-Library/UL-Templates/_assets/css/styles.css"><link rel="stylesheet" href="https://s.brightspace.com/lib/fonts/0.6.1/fonts.css"></head><body><p style="text-align: center;"><img src="../00_Images/Coding%20Task.gif" alt="" title="" data-d2l-editor-default-img-style="true" style="max-width: 100%;" role="presentation"></p>
<h1 class="page-header col-12 col-lg-10" style="text-align: center;"><span style="font-size: 32px;"><strong style="color: rgb(0, 83, 53); font-family: Lato, sans-serif;"><span style="color: rgb(0, 83, 53); font-family: Lato, sans-serif;">Task</span></strong></span></h1>
<hr>
<div class="row">
<div id="itemContainer::sectionWrapper::section::column::itemTable::item:3:" role="listitem" tabindex="0">
<div>
<div>
<h2>Before you start...</h2>
<ul>
<li>Please go through the Lesson provided and the Primary resources before attempting the task.</li>
<li>The Bayesian optimiser we will use, comes from a toolbox that may not be installed as standard. If you see error messages related to the import of skopt ('No module named skopt'), please install this module by typing 'pip install scikit_optimize' into a command prompt (e.g. Anaconda Prompt).</li>
<li>Git clone the repository in below link&nbsp;to get access to the template Jupyter notebooks.</li>
</ul>
</div>
</div>
</div>
<div id="itemContainer::sectionWrapper::section::column::itemTable::item:4:" role="listitem" tabindex="0">
<div>
<div>
<p><span style="font-family: Lato, sans-serif; font-size: 19px;"></span></p>
<p style="text-align: center;"><span style="font-family: Lato, sans-serif; font-size: 19px;"><a href="https://gitlab.com/ay2223_ce4021/groupX/e-tivity2.git"></a>https://gitlab.com/ul31/mscai/ce6002-ce6012/group<strong>X</strong>/e-tivity3.git</span><a href="https://gitlab.com/ay2223_ce4021/groupX/e-tivity3.git"><span style="font-size: 19px;"></span></a></p>
<p style="text-align: center;">Please replace the <strong>X</strong>&nbsp;in group<strong>X</strong>in above URL<strong></strong>with the number of your group.</p>
</div>
</div>
</div>
</div>
<p></p>
<hr>
<p><strong> </strong></p>
<h2>Task Description</h2>
<h3 style="text-align: left;">Task 1 (Complete first attempt by Saturday Week 5)</h3>
<p>Perform classification on dataset_1_train.csv using an SVM with linear kernel and experiment with the C-parameter to find the widest margin solution with a hard margin and a soft margin.</p>
<p><strong>Please note:</strong></p>
<ul>
<li style="font-weight: bold;"><strong>You do not need to look at out-of-sample performance. Hence, their is no '_test' set. Use all available data for training.</strong><strong></strong></li>
</ul>
<p><em>This task provides an insight in how SVMâ€™s try to find a hyperplane (which in two dimensions is a line) which divides two classes with the maximum margin on either side of the hyperplane. You can use the C-parameter as a form of regularization; with this parameter you can allow the SVM to miss-classify certain points to allow a wider margin and thus, hopefully, a better performance out-of-sample.</em></p>
<h4 style="text-align: left;">Rubric for Task 1</h4>
<p><span style="font-family: Lato, sans-serif; font-size: 19px;">Please note you will be graded on your task using the below Rubric (Task 1 elements).&nbsp;</span></p>
<p><a href="/d2l/common/dialogs/quickLink/quickLink.d2l?ou=38446&amp;type=rubric&amp;rCode=0B1740D0-E94C-4103-B4FD-F1C4C1D25EA2-56099" target="_self">Rubric E-tivity 3</a></p>
<p><span style="font-family: Lato, sans-serif; font-size: 19px;">But not until you have made your final submission. Hence, you can use week 2 to improve your initial submission.&nbsp;</span></p>
<h3 style="text-align: left;">Task 2 (Complete first attempt by Saturday Week 5)</h3>
<ol>
<li>Explore the provided data sets (dataset_2 and dataset_3) using Support Vector Machines and choose suitable kernels and hyper-parameters. Use the _train datasets to train your model after which you can test the generalisation of the resulting model using the _test datasets.<br><br><em>This task provides an insight in how a kernel can allow the SVM (a linear classifier) to be used on non-linearly separable data sets by casting the data in some higher dimensional space as determined by the kernel you choose. In addition to choosing a suitable kernel, you will find that tuning the hyper-parameters of the SVM is important. Take some time to explore various kernels and values of the hyper-parameters to get a feel for how they affect performance and then use a structured approach to arrive at your final conclusions. Take into consideration the out-of-sample error (simulated and based on theory (see lecture 14 from Learning from Data)). </em></li>
<li>Perform the same exploration for a Neural Network classifier and think carefully about the hyperparameters you wish to optimise. Also here, the goal is to explore the various hyper-parameters available in neural networks.</li>
</ol>
<p><strong>N.B.: In this task, you will optimise a number of hyperparameters resulting in a large number of possible hyperparameter combinations. Investigate how Bayesian optimisation can help to reduce the computational burden.</strong></p>
<h4 style="text-align: left;">Rubric for Task 2</h4>
<p><span style="font-family: Lato, sans-serif; font-size: 19px;">Please note you will be graded on your task using the below Rubric (Task 2 elements).&nbsp;</span></p>
<p><span style="font-family: Lato, sans-serif; font-size: 19px;"><a href="/d2l/common/dialogs/quickLink/quickLink.d2l?ou=38446&amp;type=rubric&amp;rCode=0B1740D0-E94C-4103-B4FD-F1C4C1D25EA2-56099" target="_self">Rubric E-tivity 3</a></span></p>
<p><span style="font-family: Lato, sans-serif; font-size: 19px;"> But not until you have made your final submission. Hence, you can use week 2 to improve your initial submission.&nbsp;</span></p></body></html>